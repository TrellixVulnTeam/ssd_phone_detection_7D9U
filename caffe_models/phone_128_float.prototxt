name: "Phone_DETECTION_SSD_128x128_FPGA_train"
input:"data"
input_shape{
dim:1
dim:1
dim:128
dim:128
}

layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}

layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}

layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}

layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}

layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "bn_conv4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    dilation: 1
    #binary:true
  }
}
layer {
  name: "bn_conv5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}

layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    dilation: 1
    #binary:true
  }
}
layer {
  name: "bn_conv5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}

layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    dilation: 1
    #binary:true
  }
}
layer {
  name: "bn_conv5_3"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv5_3"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "conv5_3"
  top: "fc7"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    #binary:true
  }
}
layer {
  name: "bn_fc7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_fc7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    #binary:true
  }
}
layer {
  name: "bn_conv6_1"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv6_1"
  type: "Scale"
  bottom: "conv6_1"
  top: "conv6_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}

layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 2
    #binary:true
  }
}
layer {
  name: "bn_conv6_2"
  type: "BatchNorm"
  bottom: "conv6_2"
  top: "conv6_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv6_2"
  type: "Scale"
  bottom: "conv6_2"
  top: "conv6_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    #binary:true
  }
}
layer {
  name: "bn_conv7_1"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv7_1"
  type: "Scale"
  bottom: "conv7_1"
  top: "conv7_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}

layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 2
    #binary:true
  }
}
layer {
  name: "bn_conv7_2"
  type: "BatchNorm"
  bottom: "conv7_2"
  top: "conv7_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv7_2"
  type: "Scale"
  bottom: "conv7_2"
  top: "conv7_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    #binary:true
  }
}
layer {
  name: "bn_conv8_1"
  type: "BatchNorm"
  bottom: "conv8_1"
  top: "conv8_1"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv8_1"
  type: "Scale"
  bottom: "conv8_1"
  top: "conv8_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}

layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride:2
    #binary:true
  }
}
layer {
  name: "bn_conv8_2"
  type: "BatchNorm"
  bottom: "conv8_2"
  top: "conv8_2"
  batch_norm_param {
     # use_global_stats: false
  }
}
layer {
  name: "scale_conv8_2"
  type: "Scale"
  bottom: "conv8_2"
  top: "conv8_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}

layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}

layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "conv4_3_norm_mbox_priorbox"
#   type: "PriorBox"
#   bottom: "conv4_2"
#   bottom: "data"
#   top: "conv4_3_norm_mbox_priorbox"
#   prior_box_param {
#     min_size: 25.6
#     max_size: 35.84
#     aspect_ratio: 2.0
#     aspect_ratio: 4.0
#     flip: true
#     clip: false
#     variance: 0.1
#     variance: 0.1
#     variance: 0.2
#     variance: 0.2
#   }
# }

layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}

layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "fc7_mbox_priorbox"
#   type: "PriorBox"
#   bottom: "fc7"
#   bottom: "data"
#   top: "fc7_mbox_priorbox"
#   prior_box_param {
#     min_size: 30
#     max_size: 40
#     aspect_ratio: 2.0
#     aspect_ratio: 4.0
#     flip: true
#     clip: false
#     variance: 0.1
#     variance: 0.1
#     variance: 0.2
#     variance: 0.2
#   }
# }

layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}

layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "conv6_2_mbox_priorbox"
#   type: "PriorBox"
#   bottom: "conv6_2"
#   bottom: "data"
#   top: "conv6_2_mbox_priorbox"
#   prior_box_param {
#     min_size: 40
#     max_size: 60
#     aspect_ratio: 2.0
#     aspect_ratio: 4.0
#     flip: true
#     clip: false
#     variance: 0.1
#     variance: 0.1
#     variance: 0.2
#     variance: 0.2
#   }
# }

layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}

layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "conv7_2_mbox_priorbox"
#   type: "PriorBox"
#   bottom: "conv7_2"
#   bottom: "data"
#   top: "conv7_2_mbox_priorbox"
#   prior_box_param {
#     min_size: 60
#     max_size: 70
#     aspect_ratio: 2.0
#     aspect_ratio: 4.0
#     flip: true
#     clip: false
#     variance: 0.1
#     variance: 0.1
#     variance: 0.2
#     variance: 0.2
#   }
# }

layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}

layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    
    pad: 1
    
    kernel_size: 3
    stride: 1
    #binary:true
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "conv8_2_mbox_priorbox"
#   type: "PriorBox"
#   bottom: "conv8_2"
#   bottom: "data"
#   top: "conv8_2_mbox_priorbox"
#   prior_box_param {
#     min_size: 70
#     max_size: 80
#     aspect_ratio: 2.0
#     aspect_ratio: 4.0
#     flip: true
#     clip: false
#     variance: 0.1
#     variance: 0.1
#     variance: 0.2
#     variance: 0.2
#   }
# }
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
# layer {
#   name: "mbox_priorbox"
#   type: "Concat"
#   bottom: "conv4_3_norm_mbox_priorbox"
#   bottom: "fc7_mbox_priorbox"
#   bottom: "conv6_2_mbox_priorbox"
#   bottom: "conv7_2_mbox_priorbox"
#   bottom: "conv8_2_mbox_priorbox"
#   top: "mbox_priorbox"
#   concat_param {
#     axis: 2
#   }
# }


layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  include {
    phase: TEST
  }
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 2
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  include {
    phase: TEST
  }
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  include {
    phase: TEST
  }
  flatten_param {
    axis: 1
  }
}
# layer {
#   name: "detection_out"
#   type: "DetectionOutput"
#   bottom: "mbox_loc"
#   bottom: "mbox_conf_flatten"
#   bottom: "mbox_priorbox"
#   top: "detection_out"
#   include {
#     phase: TEST
#   }
#   detection_output_param {
#     num_classes: 2
#     share_location: true
#     background_label_id: 0
#     nms_param {
#       nms_threshold: 0.44999998807907104
#       top_k: 400
#     }
#     # save_output_param {
      
#     #   label_map_file: "/home/disk/zhangmulan/project/Phone_detection/phone/labelmap_phone.prototxt"

#     # }
#     code_type: CENTER_SIZE
#     keep_top_k: 200
#     confidence_threshold: 0.009999999776482582
#   }
# }
