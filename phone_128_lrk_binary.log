I1207 13:49:39.446391 28159 train_pro.py:273] restore /home/disk1/yenanfei/DMS_phone/phone_model_pytorch/snapshot/phone_128/phone_128_float.pth
0it [00:00, ?it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/test_1.cache (1185 found, 0 missing, 0 empty, 0 duplicate, for 4571 images): 1185it [00:00, 11840.61it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/test_1.cache (2398 found, 0 missing, 0 empty, 0 duplicate, for 4571 images): 2398it [00:00, 11925.12it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/test_1.cache (3748 found, 0 missing, 0 empty, 0 duplicate, for 4571 images): 3748it [00:00, 12355.68it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/test_1.cache (4571 found, 0 missing, 0 empty, 0 duplicate, for 4571 images): 4571it [00:00, 12725.53it/s]
I1207 13:49:40.032495 28159 train_pro.py:297] training augmentation
0it [00:00, ?it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (1202 found, 0 missing, 0 empty, 0 duplicate, for 26331 images): 1202it [00:00, 12016.63it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (2397 found, 0 missing, 0 empty, 0 duplicate, for 26331 images): 2397it [00:00, 11993.74it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (3584 found, 0 missing, 0 empty, 0 duplicate, for 26331 images): 3584it [00:00, 11954.28it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (4786 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 7382it [00:00, 15046.81it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (6474 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 9070it [00:00, 14701.63it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (8074 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 10670it [00:00, 14470.77it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (9613 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 12209it [00:00, 14305.86it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (11109 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 13705it [00:00, 14219.50it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (12577 found, 0 missing, 2596 empty, 0 duplicate, for 26331 images): 15173it [00:00, 14149.81it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (13937 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 17110it [00:01, 15393.22it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (15531 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 18704it [00:01, 14943.03it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (17067 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 20240it [00:01, 14642.47it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (18562 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 21735it [00:01, 14450.68it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (20029 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 23202it [00:01, 14304.45it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (21475 found, 0 missing, 3173 empty, 0 duplicate, for 26331 images): 24648it [00:01, 14201.14it/s]Scanning labels /home/disk1/yenanfei/DMS_phone/phoneData_padding/ImageSets/trainval_1.cache (22125 found, 0 missing, 4206 empty, 0 duplicate, for 26331 images): 26331it [00:01, 15984.34it/s]----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 128, 128]             640
       BatchNorm2d-2         [-1, 64, 128, 128]             128
              ReLU-3         [-1, 64, 128, 128]               0
            Conv2d-4         [-1, 64, 128, 128]          36,928
       BatchNorm2d-5         [-1, 64, 128, 128]             128
              ReLU-6         [-1, 64, 128, 128]               0
         MaxPool2d-7           [-1, 64, 64, 64]               0
            Conv2d-8          [-1, 128, 64, 64]          73,856
       BatchNorm2d-9          [-1, 128, 64, 64]             256
             ReLU-10          [-1, 128, 64, 64]               0
           Conv2d-11          [-1, 128, 64, 64]         147,584
      BatchNorm2d-12          [-1, 128, 64, 64]             256
             ReLU-13          [-1, 128, 64, 64]               0
        MaxPool2d-14          [-1, 128, 32, 32]               0
           Conv2d-15          [-1, 256, 32, 32]         295,168
      BatchNorm2d-16          [-1, 256, 32, 32]             512
             ReLU-17          [-1, 256, 32, 32]               0
           Conv2d-18          [-1, 256, 32, 32]         590,080
      BatchNorm2d-19          [-1, 256, 32, 32]             512
             ReLU-20          [-1, 256, 32, 32]               0
        MaxPool2d-21          [-1, 256, 16, 16]               0
           Conv2d-22          [-1, 512, 16, 16]       1,180,160
      BatchNorm2d-23          [-1, 512, 16, 16]           1,024
             ReLU-24          [-1, 512, 16, 16]               0
           Conv2d-25          [-1, 512, 16, 16]       2,359,808
      BatchNorm2d-26          [-1, 512, 16, 16]           1,024
             ReLU-27          [-1, 512, 16, 16]               0
        MaxPool2d-28            [-1, 512, 8, 8]               0
           Conv2d-29            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-30            [-1, 512, 8, 8]           1,024
             ReLU-31            [-1, 512, 8, 8]               0
           Conv2d-32            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-33            [-1, 512, 8, 8]           1,024
             ReLU-34            [-1, 512, 8, 8]               0
           Conv2d-35            [-1, 512, 8, 8]       2,359,808
      BatchNorm2d-36            [-1, 512, 8, 8]           1,024
             ReLU-37            [-1, 512, 8, 8]               0
           Conv2d-38            [-1, 512, 8, 8]         262,656
      BatchNorm2d-39            [-1, 512, 8, 8]           1,024
             ReLU-40            [-1, 512, 8, 8]               0
           Conv2d-41            [-1, 256, 8, 8]         131,328
      BatchNorm2d-42            [-1, 256, 8, 8]             512
             ReLU-43            [-1, 256, 8, 8]               0
           Conv2d-44            [-1, 512, 4, 4]       1,180,160
      BatchNorm2d-45            [-1, 512, 4, 4]           1,024
             ReLU-46            [-1, 512, 4, 4]               0
           Conv2d-47            [-1, 128, 4, 4]          65,664
      BatchNorm2d-48            [-1, 128, 4, 4]             256
             ReLU-49            [-1, 128, 4, 4]               0
           Conv2d-50            [-1, 256, 2, 2]         295,168
      BatchNorm2d-51            [-1, 256, 2, 2]             512
             ReLU-52            [-1, 256, 2, 2]               0
           Conv2d-53            [-1, 128, 2, 2]          32,896
      BatchNorm2d-54            [-1, 128, 2, 2]             256
             ReLU-55            [-1, 128, 2, 2]               0
           Conv2d-56            [-1, 256, 1, 1]         295,168
      BatchNorm2d-57            [-1, 256, 1, 1]             512
             ReLU-58            [-1, 256, 1, 1]               0
           Conv2d-59           [-1, 24, 16, 16]         110,616
          Permute-60           [-1, 16, 16, 24]               0
          Flatten-61                 [-1, 6144]               0
           Conv2d-62           [-1, 12, 16, 16]          55,308
          Permute-63           [-1, 16, 16, 12]               0
          Flatten-64                 [-1, 3072]               0
           Conv2d-65             [-1, 24, 8, 8]         110,616
          Permute-66             [-1, 8, 8, 24]               0
          Flatten-67                 [-1, 1536]               0
           Conv2d-68             [-1, 12, 8, 8]          55,308
          Permute-69             [-1, 8, 8, 12]               0
          Flatten-70                  [-1, 768]               0
           Conv2d-71             [-1, 24, 4, 4]         110,616
          Permute-72             [-1, 4, 4, 24]               0
          Flatten-73                  [-1, 384]               0
           Conv2d-74             [-1, 12, 4, 4]          55,308
          Permute-75             [-1, 4, 4, 12]               0
          Flatten-76                  [-1, 192]               0
           Conv2d-77             [-1, 24, 2, 2]          55,320
          Permute-78             [-1, 2, 2, 24]               0
          Flatten-79                   [-1, 96]               0
           Conv2d-80             [-1, 12, 2, 2]          27,660
          Permute-81             [-1, 2, 2, 12]               0
          Flatten-82                   [-1, 48]               0
           Conv2d-83             [-1, 24, 1, 1]          55,320
          Permute-84             [-1, 1, 1, 24]               0
          Flatten-85                   [-1, 24]               0
           Conv2d-86             [-1, 12, 1, 1]          27,660
          Permute-87             [-1, 1, 1, 12]               0
          Flatten-88                   [-1, 12]               0
           Concat-89                 [-1, 8184]               0
           Concat-90                 [-1, 4092]               0
================================================================
Total params: 14,701,428
Trainable params: 14,701,428
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.06
Forward/backward pass size (MB): 97.78
Params size (MB): 56.08
Estimated Total Size (MB): 153.92
----------------------------------------------------------------
(3, 3) (3,) (192, 192) 3
(192, 192) 3 (3,)
(3, 192) 3 3 64
(192, 192) (192,) (192, 192) 126
(192, 192) 126 (192,)
(126, 192) 126 3 64
(192, 192) (192,) (384, 384) 149
(384, 384) 149 (192,)
(149, 384) 149 3 128
(384, 384) (384,) (384, 384) 251
(384, 384) 251 (384,)
(251, 384) 251 3 128
(384, 384) (384,) (768, 768) 293
(768, 768) 293 (384,)
(293, 768) 293 3 256
(768, 768) (768,) (768, 768) 488
(768, 768) 488 (768,)
(488, 768) 488 3 256
(768, 768) (768,) (1536, 1536) 569
(1536, 1536) 569 (768,)
(569, 1536) 569 3 512
(1536, 1536) (1536,) (1536, 1536) 872
(1536, 1536) 872 (1536,)
(872, 1536) 872 3 512
(1536, 1536) (1536,) (1536, 1536) 513
(1536, 1536) 513 (1536,)
(513, 1536) 513 3 512
(1536, 1536) (1536,) (1536, 1536) 449
(1536, 1536) 449 (1536,)
(449, 1536) 449 3 512
(1536, 1536) (1536,) (1536, 1536) 486
(1536, 1536) 486 (1536,)
(486, 1536) 486 3 512
(768, 768) (768,) (1536, 1536) 174
(1536, 1536) 174 (768,)
(174, 1536) 174 3 512
(384, 384) (384,) (768, 768) 88
(768, 768) 88 (384,)
(88, 768) 88 3 256
(384, 384) (384,) (768, 768) 39
(768, 768) 39 (384,)
(39, 768) 39 3 256
(1536, 1536) (72,) (72, 72) 51
(72, 72) 51 (72,)
(51, 72) 51 3 24
(1536, 1536) (36,) (36, 36) 25
(36, 36) 25 (36,)
(25, 36) 25 3 12
(1536, 1536) (72,) (72, 72) 54
(72, 72) 54 (72,)
(54, 72) 54 3 24
(1536, 1536) (36,) (36, 36) 22
(36, 36) 22 (36,)
(22, 36) 22 3 12
(1536, 1536) (72,) (72, 72) 39
(72, 72) 39 (72,)
(39, 72) 39 3 24
(1536, 1536) (36,) (36, 36) 11
(36, 36) 11 (36,)
(11, 36) 11 3 12
(768, 768) (72,) (72, 72) 20
(72, 72) 20 (72,)
(20, 72) 20 3 24
(768, 768) (36,) (36, 36) 6
(36, 36) 6 (36,)
(6, 36) 6 3 12
(768, 768) (72,) (72, 72) 4
(72, 72) 4 (72,)
(4, 72) 4 3 24
(768, 768) (36,) (36, 36) 1
(36, 36) 1 (36,)
(1, 36) 1 3 12
(3, 3) (3,) (192, 192) 3
(192, 192) 3 (3,)
(3, 192) 3 3 64
(192, 192) (192,) (192, 192) 126
(192, 192) 126 (192,)
(126, 192)
I1207 13:49:55.287070 28159 train_pro.py:441] ======>>> restore snapshot /home/disk1/yenanfei/DMS_phone/phone_model_pytorch/snapshot/phone_128/phone_128_lowrank_continue.pth
 126 3 64
(192, 192) (192,) (384, 384) 149
(384, 384) 149 (192,)
(149, 384) 149 3 128
(384, 384) (384,) (384, 384) 251
(384, 384) 251 (384,)
(251, 384) 251 3 128
(384, 384) (384,) (768, 768) 293
(768, 768) 293 (384,)
(293, 768) 293 3 256
(768, 768) (768,) (768, 768) 488
(768, 768) 488 (768,)
(488, 768) 488 3 256
(768, 768) (768,) (1536, 1536) 569
(1536, 1536) 569 (768,)
(569, 1536) 569 3 512
(1536, 1536) (1536,) (1536, 1536) 872
(1536, 1536) 872 (1536,)
(872, 1536) 872 3 512
(1536, 1536) (1536,) (1536, 1536) 513
(1536, 1536) 513 (1536,)
(513, 1536) 513 3 512
(1536, 1536) (1536,) (1536, 1536) 449
(1536, 1536) 449 (1536,)
(449, 1536) 449 3 512
(1536, 1536) (1536,) (1536, 1536) 486
(1536, 1536) 486 (1536,)
(486, 1536) 486 3 512
(768, 768) (768,) (1536, 1536) 174
(1536, 1536) 174 (768,)
(174, 1536) 174 3 512
(384, 384) (384,) (768, 768) 88
(768, 768) 88 (384,)
(88, 768) 88 3 256
(384, 384) (384,) (768, 768) 39
(768, 768) 39 (384,)
(39, 768) 39 3 256
(1536, 1536) (72,) (72, 72) 51
(72, 72) 51 (72,)
(51, 72) 51 3 24
(1536, 1536) (36,) (36, 36) 25
(36, 36) 25 (36,)
(25, 36) 25 3 12
(1536, 1536) (72,) (72, 72) 54
(72, 72) 54 (72,)
(54, 72) 54 3 24
(1536, 1536) (36,) (36, 36) 22
(36, 36) 22 (36,)
(22, 36) 22 3 12
(1536, 1536) (72,) (72, 72) 39
(72, 72) 39 (72,)
(39, 72) 39 3 24
(1536, 1536) (36,) (36, 36) 11
(36, 36) 11 (36,)
(11, 36) 11 3 12
(768, 768) (72,) (72, 72) 20
(72, 72) 20 (72,)
(20, 72) 20 3 24
(768, 768) (36,) (36, 36) 6
(36, 36) 6 (36,)
(6, 36) 6 3 12
(768, 768) (72,) (72, 72) 4
(72, 72) 4 (72,)
(4, 72) 4 3 24
(768, 768) (36,) (36, 36) 1
(36, 36) 1 (36,)
(1, 36) 1 3 12
DataParallel(
  (module): phone_128_float(
    (conv1_1): Sequential(
      (conv1_1_v): Conv2d(1, 3, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv1_1_h): Conv2d(3, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv1_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu1_1): ReLU(inplace=True)
    (conv1_2): Sequential(
      (conv1_2_v): Conv2d(64, 126, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv1_2_h): Conv2d(126, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu1_2): ReLU(inplace=True)
    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2_1): Sequential(
      (conv2_1_v): Conv2d(64, 149, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv2_1_h): Conv2d(149, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv2_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu2_1): ReLU(inplace=True)
    (conv2_2): Sequential(
      (conv2_2_v): Conv2d(128, 251, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv2_2_h): Conv2d(251, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv2_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu2_2): ReLU(inplace=True)
    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3_1): Sequential(
      (conv3_1_v): Conv2d(128, 293, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv3_1_h): Conv2d(293, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu3_1): ReLU(inplace=True)
    (conv3_2): Sequential(
      (conv3_2_v): Conv2d(256, 488, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv3_2_h): Conv2d(488, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu3_2): ReLU(inplace=True)
    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv4_1): Sequential(
      (conv4_1_v): Conv2d(256, 569, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_1_h): Conv2d(569, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu4_1): ReLU(inplace=True)
    (conv4_2): Sequential(
      (conv4_2_v): Conv2d(512, 872, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_2_h): Conv2d(872, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu4_2): ReLU(inplace=True)
    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv5_1): Sequential(
      (conv5_1_v): Conv2d(512, 513, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_1_h): Conv2d(513, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_1): ReLU(inplace=True)
    (conv5_2): Sequential(
      (conv5_2_v): Conv2d(512, 449, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_2_h): Conv2d(449, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_2): ReLU(inplace=True)
    (conv5_3): Sequential(
      (conv5_3_v): Conv2d(512, 486, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_3_h): Conv2d(486, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_3): ReLU(inplace=True)
    (fc7): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (bn_fc7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu7): ReLU(inplace=True)
    (conv6_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv6_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6_1_relu): ReLU(inplace=True)
    (conv6_2): Sequential(
      (conv6_2_v): Conv2d(256, 174, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv6_2_h): Conv2d(174, 512, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv6_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6_2_relu): ReLU(inplace=True)
    (conv7_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv7_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv7_1_relu): ReLU(inplace=True)
    (conv7_2): Sequential(
      (conv7_2_v): Conv2d(128, 88, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv7_2_h): Conv2d(88, 256, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv7_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv7_2_relu): ReLU(inplace=True)
    (conv8_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv8_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv8_1_relu): ReLU(inplace=True)
    (conv8_2): Sequential(
      (conv8_2_v): Conv2d(128, 39, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv8_2_h): Conv2d(39, 256, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv8_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv8_2_relu): ReLU(inplace=True)
    (conv4_3_norm_mbox_loc): Sequential(
      (conv4_3_norm_mbox_loc_v): Conv2d(512, 51, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_3_norm_mbox_loc_h): Conv2d(51, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv4_3_norm_mbox_loc_perm): Permute()
    (conv4_3_norm_mbox_loc_flat): Flatten()
    (conv4_3_norm_mbox_conf): Sequential(
      (conv4_3_norm_mbox_conf_v): Conv2d(512, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_3_norm_mbox_conf_h): Conv2d(25, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv4_3_norm_mbox_conf_perm): Permute()
    (conv4_3_norm_mbox_conf_flat): Flatten()
    (fc7_mbox_loc): Sequential(
      (fc7_mbox_loc_v): Conv2d(512, 54, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (fc7_mbox_loc_h): Conv2d(54, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (fc7_mbox_loc_perm): Permute()
    (fc7_mbox_loc_flat): Flatten()
    (fc7_mbox_conf): Sequential(
      (fc7_mbox_conf_v): Conv2d(512, 22, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (fc7_mbox_conf_h): Conv2d(22, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (fc7_mbox_conf_perm): Permute()
    (fc7_mbox_conf_flat): Flatten()
    (conv6_2_mbox_loc): Sequential(
      (conv6_2_mbox_loc_v): Conv2d(512, 39, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv6_2_mbox_loc_h): Conv2d(39, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv6_2_mbox_loc_perm): Permute()
    (conv6_2_mbox_loc_flat): Flatten()
    (conv6_2_mbox_conf): Sequential(
      (conv6_2_mbox_conf_v): Conv2d(512, 11, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv6_2_mbox_conf_h): Conv2d(11, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv6_2_mbox_conf_perm): Permute()
    (conv6_2_mbox_conf_flat): Flatten()
    (conv7_2_mbox_loc): Sequential(
      (conv7_2_mbox_loc_v): Conv2d(256, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv7_2_mbox_loc_h): Conv2d(20, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv7_2_mbox_loc_perm): Permute()
    (conv7_2_mbox_loc_flat): Flatten()
    (conv7_2_mbox_conf): Sequential(
      (conv7_2_mbox_conf_v): Conv2d(256, 6, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv7_2_mbox_conf_h): Conv2d(6, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv7_2_mbox_conf_perm): Permute()
    (conv7_2_mbox_conf_flat): Flatten()
    (conv8_2_mbox_loc): Sequential(
      (conv8_2_mbox_loc_v): Conv2d(256, 4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv8_2_mbox_loc_h): Conv2d(4, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv8_2_mbox_loc_perm): Permute()
    (conv8_2_mbox_loc_flat): Flatten()
    (conv8_2_mbox_conf): Sequential(
      (conv8_2_mbox_conf_v): Conv2d(256, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv8_2_mbox_conf_h): Conv2d(1, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv8_2_mbox_conf_perm): Permute()
    (conv8_2_mbox_conf_flat): Flatten()
    (mbox_loc): Concat()
    (mbox_conf): Concat()
    (softmax): Softmax(dim=-1)
  )
)
DataParallel(
  (module): phone_128_float(
    (conv1_1): Sequential(
      (conv1_1_v): IRConv2d(1, 3, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv1_1_h): IRConv2d(3, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv1_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu1_1): ReLU(inplace=True)
    (conv1_2): Sequential(
      (conv1_2_v): IRConv2d(64, 126, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv1_2_h): IRConv2d(126, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu1_2): ReLU(inplace=True)
    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2_1): Sequential(
      (conv2_1_v): IRConv2d(64, 149, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv2_1_h): IRConv2d(149, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv2_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu2_1): ReLU(inplace=True)
    (conv2_2): Sequential(
      (conv2_2_v): IRConv2d(128, 251, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv2_2_h): IRConv2d(251, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv2_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu2_2): ReLU(inplace=True)
    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3_1): Sequential(
      (conv3_1_v): IRConv2d(128, 293, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv3_1_h): IRConv2d(293, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu3_1): ReLU(inplace=True)
    (conv3_2): Sequential(
      (conv3_2_v): IRConv2d(256, 488, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv3_2_h): IRConv2d(488, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu3_2): ReLU(inplace=True)
    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv4_1): Sequential(
      (conv4_1_v): IRConv2d(256, 569, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_1_h): IRConv2d(569, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu4_1): ReLU(inplace=True)
    (conv4_2): Sequential(
      (conv4_2_v): IRConv2d(512, 872, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_2_h): IRConv2d(872, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu4_2): ReLU(inplace=True)
    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv5_1): Sequential(
      (conv5_1_v): IRConv2d(512, 513, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_1_h): IRConv2d(513, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_1): ReLU(inplace=True)
    (conv5_2): Sequential(
      (conv5_2_v): IRConv2d(512, 449, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_2_h): IRConv2d(449, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_2): ReLU(inplace=True)
    (conv5_3): Sequential(
      (conv5_3_v): IRConv2d(512, 486, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv5_3_h): IRConv2d(486, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (bn_conv5_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5_3): ReLU(inplace=True)
    (fc7): IRConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (bn_fc7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu7): ReLU(inplace=True)
    (conv6_1): IRConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv6_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6_1_relu): ReLU(inplace=True)
    (conv6_2): Sequential(
      (conv6_2_v): IRConv2d(256, 174, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv6_2_h): IRConv2d(174, 512, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv6_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6_2_relu): ReLU(inplace=True)
    (conv7_1): IRConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv7_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv7_1_relu): ReLU(inplace=True)
    (conv7_2): Sequential(
      (conv7_2_v): IRConv2d(128, 88, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv7_2_h): IRConv2d(88, 256, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv7_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv7_2_relu): ReLU(inplace=True)
    (conv8_1): IRConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    (bn_conv8_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv8_1_relu): ReLU(inplace=True)
    (conv8_2): Sequential(
      (conv8_2_v): IRConv2d(128, 39, kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))
      (conv8_2_h): IRConv2d(39, 256, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))
    )
    (bn_conv8_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv8_2_relu): ReLU(inplace=True)
    (conv4_3_norm_mbox_loc): Sequential(
      (conv4_3_norm_mbox_loc_v): IRConv2d(512, 51, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_3_norm_mbox_loc_h): IRConv2d(51, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv4_3_norm_mbox_loc_perm): Permute()
    (conv4_3_norm_mbox_loc_flat): Flatten()
    (conv4_3_norm_mbox_conf): Sequential(
      (conv4_3_norm_mbox_conf_v): IRConv2d(512, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv4_3_norm_mbox_conf_h): IRConv2d(25, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv4_3_norm_mbox_conf_perm): Permute()
    (conv4_3_norm_mbox_conf_flat): Flatten()
    (fc7_mbox_loc): Sequential(
      (fc7_mbox_loc_v): IRConv2d(512, 54, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (fc7_mbox_loc_h): IRConv2d(54, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (fc7_mbox_loc_perm): Permute()
    (fc7_mbox_loc_flat): Flatten()
    (fc7_mbox_conf): Sequential(
      (fc7_mbox_conf_v): IRConv2d(512, 22, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (fc7_mbox_conf_h): IRConv2d(22, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (fc7_mbox_conf_perm): Permute()
    (fc7_mbox_conf_flat): Flatten()
    (conv6_2_mbox_loc): Sequential(
      (conv6_2_mbox_loc_v): IRConv2d(512, 39, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv6_2_mbox_loc_h): IRConv2d(39, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv6_2_mbox_loc_perm): Permute()
    (conv6_2_mbox_loc_flat): Flatten()
    (conv6_2_mbox_conf): Sequential(
      (conv6_2_mbox_conf_v): IRConv2d(512, 11, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv6_2_mbox_conf_h): IRConv2d(11, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv6_2_mbox_conf_perm): Permute()
    (conv6_2_mbox_conf_flat): Flatten()
    (conv7_2_mbox_loc): Sequential(
      (conv7_2_mbox_loc_v): IRConv2d(256, 20, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv7_2_mbox_loc_h): IRConv2d(20, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv7_2_mbox_loc_perm): Permute()
    (conv7_2_mbox_loc_flat): Flatten()
    (conv7_2_mbox_conf): Sequential(
      (conv7_2_mbox_conf_v): IRConv2d(256, 6, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv7_2_mbox_conf_h): IRConv2d(6, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv7_2_mbox_conf_perm): Permute()
    (conv7_2_mbox_conf_flat): Flatten()
    (conv8_2_mbox_loc): Sequential(
      (conv8_2_mbox_loc_v): IRConv2d(256, 4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv8_2_mbox_loc_h): IRConv2d(4, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv8_2_mbox_loc_perm): Permute()
    (conv8_2_mbox_loc_flat): Flatten()
    (conv8_2_mbox_conf): Sequential(
      (conv8_2_mbox_conf_v): IRConv2d(256, 1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (conv8_2_mbox_conf_h): IRConv2d(1, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
    )
    (conv8_2_mbox_conf_perm): Permute()
    (conv8_2_mbox_conf_flat): Flatten()
    (mbox_loc): Concat()
    (mbox_conf): Concat()
    (softmax): Softmax(dim=-1)
  )
)I1207 13:49:55.435436 28159 TrainVal3.py:113] ==>>> supervised train batches:205

1
SGD (
Parameter Group 0
    dampening: 0
    lr: 1e-06
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)
  0%|          | 0/100 [00:00<?, ?it/s]I1207 13:50:02.230723 28159 TrainVal3.py:307] ==>>> epoch: 0,batch index: 0 ,lr:1e-06 ,train loss: nan ssd_loc:nan ssd_conf:nan
W1207 13:50:02.231185 28159 x2num.py:14] NaN or Inf found in input tensor.
W1207 13:50:02.235158 28159 x2num.py:14] NaN or Inf found in input tensor.
W1207 13:50:02.235618 28159 x2num.py:14] NaN or Inf found in input tensor.
